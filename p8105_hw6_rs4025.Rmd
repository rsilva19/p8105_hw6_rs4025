---
title: "Homework 6"
author: "Rebecca Silva"
date: "11/15/2019"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(viridis)
library(modelr)
library(mgcv)


knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	message = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
theme_set(theme_minimal() + theme(legend.position = "bottom"))
```


### Problem 1 

```{r, warning= FALSE, message=FALSE}
# data read in 
birthweight = 
  read_csv("./data/birthweight.csv") %>% 
  mutate(babysex = factor(babysex, 
                          labels = c("male", "female")), 
         frace = factor(frace, 
                        labels = c("white", "black", "asian", "puerto rican", "other")),
         malform = factor(malform, 
                          labels = c("absent", "present")), 
         mrace = factor(mrace, 
                        labels = c("white", "black", "asian", "puerto rican")))


```

Since we are starting off with 20 variables, we elimate some based on general hypotheses about variables that might not explain birthweight well and based on their respective correlation to birthweight `wgt`, shown below.   

```{r, warning = FALSE}
# correalation matrix 
birthweight_numeric = 
  select_if(birthweight, is.numeric)
round(cor(birthweight_numeric %>% select(-bwt), birthweight %>% pull(bwt)), 2)
```


In order to predict birthweight, we want to understand how our given variables relate to birthweight, and ultimately, include the most important predictors of birthweight in our model. We will focus on the variables, `bhead`, `blength`, `gaweeks`, `wtgain`, `delwt`, `mrace`, `frace`, `babysex`, and `smoken`. 

We include some graphical dispictions of the relationships that seem to have the strongest association. A linear relationship looks likely between many of the variables and `birthweight`. 
```{r, warning = FALSE}
# baby’s head circumference at birth (centimeters)
birthweight %>% 
  ggplot(aes(x = bhead, y = bwt)) + 
  geom_point(alpha = .5)

# baby’s length at birth (centimeteres)
birthweight %>% 
  ggplot(aes(x = blength, y = bwt)) + 
  geom_point(alpha = .5)

# baby's gestational age
birthweight %>% 
  ggplot(aes(x = gaweeks, y = bwt)) + 
  geom_point(alpha = .5)
```


```{r}
# use criterion approach to identify 'best' subset
library(leaps)
subset = regsubsets(bwt ~ bhead + blength + gaweeks + wtgain + delwt + mrace + frace + babysex  + smoken, data = birthweight)
summary(subset)
leaps(x =hospital_subdata[,2:7], y =hospital_subdata[,1], nbest =2, method ="")

x = birthweight %>% 
        select(bhead, blength,gaweeks,wtgain,delwt,mrace,frace,babysex ,smoken)
y = birthweight %>% pull(bwt)
# criterion based on adj r^2
leaps(x = x, 
      y = y, 
      nbest =2, 
      method ="adjr2")
```


```{r}
linear_mod = lm(bwt ~ bhead + blength + gaweeks + wtgain + smoken, data = birthweight)
linear_mod %>% broom::glance()

mod1 = lm(bwt ~ bhead*blength*gaweeks*wtgain, data = birthweight)
mod1 %>% broom::glance()
mod1 %>% broom::tidy()

mod2 = lm(bwt~ ., data = birthweight)
summary(mod2)

# adding all continuous that seem to have strong correlation and adding all catergorical except malform
mod3 = lm(bwt~ bhead + blength + gaweeks + wtgain + delwt + mrace + frace + babysex  + smoken, data = birthweight)
summary(mod3)

# add interactions for sex 
mod4 = lm(bwt~ (bhead + blength + gaweeks + wtgain + delwt + mrace + frace +  + smoken)*babysex, data = birthweight)
summary(mod4)

# only keep significant interactions
mod4 = lm(bwt~ bhead*babysex + blength + gaweeks + wtgain + delwt + smoken+ mrace + frace, data = birthweight)
summary(mod4)

# check for multicollinearity 
car::vif(mod4)

# take out dad race bc high correlation with mom race 
mod4 = lm(bwt~ bhead+ babysex + blength + gaweeks + wtgain + delwt + mrace + smoken, data = birthweight)
summary(mod4)
car::vif(mod4)

# do some anovas - partial f-tests
mod5 = lm(bwt~ bhead*babysex + blength + gaweeks + wtgain + delwt + mrace  + smoken, data = birthweight)
anova(mod4, mod5) # keep interaction

mod_full = lm(bwt ~ ., data = birthweight)
anova(mod5, mod_full) # says i should do full
summary(mod_full)
summary(mod5)

# check for multicollinearity 
car::vif(mod5)

mod5 %>% 
  broom::tidy() %>% 
  select(term, estimate, p.value) %>% 
  knitr::kable(digits = 3)

```

winner for now: mod5
Even though a Nested F- test suggests the full model is more usual (significant F-stat), since the adjusted $R^2$ only increases from my model to a full model by 0.001, and my model is simpler and more interpretable, I will go with the smaller model using `bhead`, `babysex`, `bhead*babysex`, `blength`, `gaweeks`, `wtgain`, `delwt`, `mrace`, and `smoken` as predictors. 
The proposed regression model: bwt~ bhead*babysex + blength + gaweeks + wtgain + delwt + mrace  + smoken

# show a plot of model residuals against fitted values – use add_predictions and add_residuals in making this plot.
```{r, warning = FALSE, message= FALSE}
resid_df = modelr::add_residuals(birthweight, mod5)
pred_df = modelr::add_predictions(birthweight, mod5)
bwt_pred = left_join(resid_df, pred_df)

bwt_pred %>% 
  ggplot(aes(x = pred, y = resid)) + geom_point()

birthweight %>% 
  modelr::add_residuals(mod5) %>% 
  ggplot(aes(x = bhead, y = resid)) + geom_point()

birthweight %>% 
  modelr::add_residuals(mod5) %>% 
  ggplot(aes(x = blength, y = resid)) + geom_point()
```

## Comparing with two other models 

* birthweight ~ blength + gaweeks

* birthweight ~ bhead * blength * babysex

## Checking residuals 
```{r}
mod1 = lm(bwt ~ blength + gaweeks, data = birthweight)
mod2 = lm(bwt ~ bhead*blength*babysex, data = birthweight)

cv_df = 
  crossv_mc(birthweight, 100) 
cv_df =
  cv_df %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble))

birthweight_cv = 
  cv_df %>% 
  mutate(mod  = map(train, ~lm(bwt~ bhead*babysex + blength + gaweeks + wtgain + delwt + mrace  + smoken, data = .x)),
         mod1  = map(train, ~lm(bwt ~ blength + gaweeks, data = .x)),
         mod2  = map(train, ~lm(bwt ~ bhead * blength * babysex, data = .x))) %>% 
  mutate(rmse_mod = map2_dbl(mod , test, ~rmse(model = .x, data = .y)),
         rmse_mod1 = map2_dbl(mod1, test, ~rmse(model = .x, data = .y)), 
         rmse_mod2 = map2_dbl(mod2, test, ~rmse(model = .x, data = .y)))
```


```{r}
birthweight_cv %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + geom_violin()
```


Chosen model has smalles rmse which is a good way to check if model has predictions with large variances. It seems that on average the rmse is lowest in my chosen model. 

```{r}
smooth_mod = gam(bwt ~ s(bhead) + s(blength) + s(gaweeks) + s(wtgain), data = birthweight)
```



### Problem 2 

```{r}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())
```

```{r}

get_terms = function(model){
  output1 = 
    model %>% 
    broom::glance() %>% 
    select(r.squared)
  
  output2 = 
    model %>% 
    broom::tidy() %>% 
    select(estimate)
  
  return(
    df = tibble(
      r_squared = as.numeric(output1), 
      log_b1b2 = log(output2$estimate[1]*output2$estimate[2])
    ))
}
set.seed(1)
weather_boot = 
  weather_df %>% 
  modelr::bootstrap(n = 5000) %>% # change to 5000
  mutate(
    models = map(strap, ~lm(tmax ~ tmin, data = .x)),
    results = map(models, get_terms)) %>% 
  select(results) %>% 
  unnest(results) 
```

```{r}
# plot distributions
weather_boot %>% 
  ggplot(aes( x = r_squared)) +
  geom_density() +
  xlim(c(.87, .95)) +
  labs(
    title = "Distribution of R-Squared", 
    x = "r-squared"
  ) +
  theme(plot.title = element_text(hjust = 0.5))

weather_boot %>% 
  ggplot(aes( x = log_b1b2)) +
  geom_density() +
  xlim(c(1.9, 2.1)) +
  labs(
    title = "Distribution of log(Beta1*Beta0)", 
    x = "log(b1*b0)"
  ) +
  theme(plot.title = element_text(hjust = 0.5))
  
```

# describe distributions

The distribution of $R^2$ is symmetric and unimodel with a sharp peak around 0.912. It seems that there is small variation on its values as most fits between 0.88 and 0.94. 
  
R-Squared 95% CI:
```{r}
round(quantile(weather_boot$r_squared, probs = c(0.025, 0.975)), digits = 3) 
```

95% of our boothstrap samples obtained an $R^2$ value between 0.894 and 0.927.

The distribution of log(Beta1*Beta0) is symmetric and centered around 2.02.

Log(B1*B0) 95% CI:
```{r}
round(quantile(weather_boot$log_b1b2, probs = c(0.025, 0.975)), digits = 3) 
```

95% of our boothstrap samples obtained a log(B1*B0) value between 1.965 and 2.059.

